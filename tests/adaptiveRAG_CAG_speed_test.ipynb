{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:04:36.658621Z",
     "start_time": "2024-11-29T08:04:12.303888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cag.embeddings import SentenceTransformerEmbeddings\n",
    "from cag.models import ChatOllama\n",
    "\n",
    "embeddings_model = SentenceTransformerEmbeddings('sentence-transformers/all-mpnet-base-v2')\n",
    "qwen = ChatOllama(model='qwen2.5', temprature=0.001)\n",
    "llama = ChatOllama(model='llama3.2', temprature=0.001)"
   ],
   "id": "e9b294f896160744",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laptopkaran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Laptopkaran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Speed Test of CAG on Intel Core i7 1165G7",
   "id": "1692239406987552"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:05:41.128697Z",
     "start_time": "2024-11-29T08:05:40.864433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import datasets\n",
    "\n",
    "with open('F:\\\\OneDrive\\\\Desktop\\\\Research\\\\Dataset\\\\CRSB-Texts.json', 'r') as f:\n",
    "    crsb = json.load(f)\n",
    "\n",
    "crsb = crsb['amazon_rainforest']\n",
    "\n",
    "\n",
    "squad = datasets.load_dataset('rajpurkar/squad')\n",
    "squad = squad['validation'].shuffle()\n",
    "squad = squad[:100]\n",
    "\n",
    "contexts = crsb['contents']\n",
    "questions = squad['question']"
   ],
   "id": "fc97a1740e613f16",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since rajpurkar/squad couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at F:\\Models\\huggingface\\datasets\\rajpurkar___squad\\plain_text\\0.0.0\\7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Thu Nov 28 23:06:36 2024).\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T08:29:40.250227Z",
     "start_time": "2024-11-29T08:29:37.372250Z"
    }
   },
   "source": [
    "from cag.vector_candidates.vc import VectorCandidates\n",
    "from cag.gate.vector_candidates import VectorCandidatesGate\n",
    "\n",
    "with open('F:\\\\OneDrive\\\\Desktop\\\\Research\\\\Dataset\\\\CRSB-Embeddings-MPNET.json', 'r') as f:\n",
    "    crsb = json.load(f)\n",
    "\n",
    "crsb_contexts_embeddings = crsb['amazon_rainforest']['contents']\n",
    "crsb_pseudo_queries_embeddings = crsb['amazon_rainforest']['questions']\n",
    "VC = VectorCandidates(contexts=[crsb_contexts_embeddings], questions=[crsb_pseudo_queries_embeddings])\n",
    "\n",
    "Gate = VectorCandidatesGate(vc=VC, embedding_model=embeddings_model)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:33:31.771015Z",
     "start_time": "2024-11-29T08:33:27.727131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "acc = []\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    a = time()\n",
    "    _, needs_retrieval = Gate(question, policy= 95, threshold= 0.0)\n",
    "    b = time()\n",
    "    acc.append(needs_retrieval)\n",
    "    results.append(b - a)\n",
    "    "
   ],
   "id": "54920389929979da",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:33:41.217405Z",
     "start_time": "2024-11-29T08:33:41.199350Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Mean of the execution : {np.mean(np.array(results))}')",
   "id": "5a9f2b349822f4fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the execution : 0.040327818393707277\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:33:42.026504Z",
     "start_time": "2024-11-29T08:33:42.009217Z"
    }
   },
   "cell_type": "code",
   "source": "print(acc.count(False))",
   "id": "28c0dae39939df70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Speed Test of Adaptive-RAG on Llama 3.2 on Ollama - Intel Core i7 1165G7",
   "id": "353a71b944f7bda3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:36:48.289884Z",
     "start_time": "2024-11-29T08:36:48.284733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def query_classification(context, query):\n",
    "    prompt = f\"\"\"I will give you a context and a query . please determine if the context is related to the query or not. this means that the context can potentially answer the query or not. \n",
    "    first provide the reasons that why the context is related to the query or not; then result a YES or NO answer which determines the context can answer the question or not.\n",
    "    \n",
    "    This is the context :\n",
    "    Context : {context}\n",
    "    \n",
    "    Here is the Query :\n",
    "    Query : {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = prompt.format(context = context, query = query)\n",
    "    \n",
    "    result = llama.invoke(prompt).content\n",
    "    \n",
    "    result = result.lower()\n",
    "    \n",
    "    score = True if result.count('yes') > result.count('no') else False\n",
    "    \n",
    "    return result, score"
   ],
   "id": "29eee4275afcee0d",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T09:02:07.572896Z",
     "start_time": "2024-11-29T08:36:55.592141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "adapt_reasons = []\n",
    "classified = []\n",
    "times = []\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    \n",
    "    a = time()\n",
    "    x, y = query_classification(contexts[i], question)\n",
    "    adapt_reasons.append(x)\n",
    "    classified.append(y)\n",
    "    b = time()\n",
    "    \n",
    "    times.append(b-a)\n",
    "    \n",
    "    print(f'Question {i} processed in {b - a} seconds')\n",
    "    \n",
    "print(np.mean(np.array(times)))"
   ],
   "id": "a29d2e2944ab4e67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 0 processed in 16.249415159225464 seconds\n",
      "Question 1 processed in 13.60577654838562 seconds\n",
      "Question 2 processed in 10.488154649734497 seconds\n",
      "Question 3 processed in 13.914227962493896 seconds\n",
      "Question 4 processed in 14.02314281463623 seconds\n",
      "Question 5 processed in 16.04472279548645 seconds\n",
      "Question 6 processed in 13.128191471099854 seconds\n",
      "Question 7 processed in 13.03741979598999 seconds\n",
      "Question 8 processed in 9.17011547088623 seconds\n",
      "Question 9 processed in 10.818281412124634 seconds\n",
      "Question 10 processed in 15.283581972122192 seconds\n",
      "Question 11 processed in 16.783185958862305 seconds\n",
      "Question 12 processed in 25.952962398529053 seconds\n",
      "Question 13 processed in 21.270318508148193 seconds\n",
      "Question 14 processed in 16.901559114456177 seconds\n",
      "Question 15 processed in 13.20402717590332 seconds\n",
      "Question 16 processed in 27.559168100357056 seconds\n",
      "Question 17 processed in 19.753660202026367 seconds\n",
      "Question 18 processed in 15.804246425628662 seconds\n",
      "Question 19 processed in 19.07246971130371 seconds\n",
      "Question 20 processed in 19.168843030929565 seconds\n",
      "Question 21 processed in 14.194708824157715 seconds\n",
      "Question 22 processed in 31.698413372039795 seconds\n",
      "Question 23 processed in 15.802358388900757 seconds\n",
      "Question 24 processed in 12.749229192733765 seconds\n",
      "Question 25 processed in 15.705145120620728 seconds\n",
      "Question 26 processed in 9.818264961242676 seconds\n",
      "Question 27 processed in 20.064902544021606 seconds\n",
      "Question 28 processed in 10.36462140083313 seconds\n",
      "Question 29 processed in 22.89337396621704 seconds\n",
      "Question 30 processed in 23.80292844772339 seconds\n",
      "Question 31 processed in 12.12197208404541 seconds\n",
      "Question 32 processed in 8.736053943634033 seconds\n",
      "Question 33 processed in 15.406992197036743 seconds\n",
      "Question 34 processed in 18.23601984977722 seconds\n",
      "Question 35 processed in 14.767266035079956 seconds\n",
      "Question 36 processed in 12.245415449142456 seconds\n",
      "Question 37 processed in 12.419576644897461 seconds\n",
      "Question 38 processed in 12.451838731765747 seconds\n",
      "Question 39 processed in 13.16044282913208 seconds\n",
      "Question 40 processed in 10.990707397460938 seconds\n",
      "Question 41 processed in 17.309720039367676 seconds\n",
      "Question 42 processed in 18.956639766693115 seconds\n",
      "Question 43 processed in 20.61944079399109 seconds\n",
      "Question 44 processed in 10.16165566444397 seconds\n",
      "Question 45 processed in 13.0402991771698 seconds\n",
      "Question 46 processed in 11.133200645446777 seconds\n",
      "Question 47 processed in 11.23201322555542 seconds\n",
      "Question 48 processed in 13.838977336883545 seconds\n",
      "Question 49 processed in 9.991716623306274 seconds\n",
      "Question 50 processed in 12.212783813476562 seconds\n",
      "Question 51 processed in 14.463778972625732 seconds\n",
      "Question 52 processed in 17.86013913154602 seconds\n",
      "Question 53 processed in 11.324347972869873 seconds\n",
      "Question 54 processed in 11.076957702636719 seconds\n",
      "Question 55 processed in 12.932185173034668 seconds\n",
      "Question 56 processed in 14.231123447418213 seconds\n",
      "Question 57 processed in 14.409942150115967 seconds\n",
      "Question 58 processed in 17.113093614578247 seconds\n",
      "Question 59 processed in 13.508509635925293 seconds\n",
      "Question 60 processed in 15.428471326828003 seconds\n",
      "Question 61 processed in 12.887060165405273 seconds\n",
      "Question 62 processed in 12.900017261505127 seconds\n",
      "Question 63 processed in 12.562183856964111 seconds\n",
      "Question 64 processed in 15.485610961914062 seconds\n",
      "Question 65 processed in 11.045599937438965 seconds\n",
      "Question 66 processed in 13.11881971359253 seconds\n",
      "Question 67 processed in 12.04168438911438 seconds\n",
      "Question 68 processed in 9.141233444213867 seconds\n",
      "Question 69 processed in 13.356110095977783 seconds\n",
      "Question 70 processed in 23.42442560195923 seconds\n",
      "Question 71 processed in 25.37266182899475 seconds\n",
      "Question 72 processed in 11.814985513687134 seconds\n",
      "Question 73 processed in 11.812297582626343 seconds\n",
      "Question 74 processed in 16.280245780944824 seconds\n",
      "Question 75 processed in 8.907326459884644 seconds\n",
      "Question 76 processed in 13.91774606704712 seconds\n",
      "Question 77 processed in 8.945498704910278 seconds\n",
      "Question 78 processed in 17.171473503112793 seconds\n",
      "Question 79 processed in 10.945122718811035 seconds\n",
      "Question 80 processed in 17.42540192604065 seconds\n",
      "Question 81 processed in 15.25185251235962 seconds\n",
      "Question 82 processed in 17.59445309638977 seconds\n",
      "Question 83 processed in 16.812140226364136 seconds\n",
      "Question 84 processed in 11.473771333694458 seconds\n",
      "Question 85 processed in 19.817058801651 seconds\n",
      "Question 86 processed in 19.192346334457397 seconds\n",
      "Question 87 processed in 14.048699378967285 seconds\n",
      "Question 88 processed in 22.62085270881653 seconds\n",
      "Question 89 processed in 10.18513011932373 seconds\n",
      "Question 90 processed in 21.147132396697998 seconds\n",
      "Question 91 processed in 16.95949125289917 seconds\n",
      "Question 92 processed in 9.52711033821106 seconds\n",
      "Question 93 processed in 19.129111528396606 seconds\n",
      "Question 94 processed in 13.009990453720093 seconds\n",
      "Question 95 processed in 8.726630210876465 seconds\n",
      "Question 96 processed in 17.113475799560547 seconds\n",
      "Question 97 processed in 20.770350217819214 seconds\n",
      "Question 98 processed in 19.154261827468872 seconds\n",
      "Question 99 processed in 11.174378871917725 seconds\n",
      "15.119724411964416\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "29cfb69800b0381a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
