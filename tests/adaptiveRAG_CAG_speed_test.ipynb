{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from cag.embeddings import SentenceTransformerEmbeddings\n",
    "from cag.models import ChatOllama\n",
    "print(1)\n",
    "embeddings_model = SentenceTransformerEmbeddings('sentence-transformers/all-mpnet-base-v2')\n",
    "qwen = ChatOllama(model='qwen2.5', temprature=0.001)\n",
    "llama = ChatOllama(model='llama3.2', temprature=0.001)"
   ],
   "id": "e9b294f896160744",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Speed Test of CAG on Intel Core i7 1165G7",
   "id": "1692239406987552"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:05:41.128697Z",
     "start_time": "2024-11-29T08:05:40.864433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import datasets\n",
    "\n",
    "with open('F:\\\\OneDrive\\\\Desktop\\\\Research\\\\Dataset\\\\CRSB-Texts.json', 'r') as f:\n",
    "    crsb = json.load(f)\n",
    "\n",
    "crsb = crsb['amazon_rainforest']\n",
    "\n",
    "\n",
    "squad = datasets.load_dataset('rajpurkar/squad')\n",
    "squad = squad['validation'].shuffle()\n",
    "squad = squad[:100]\n",
    "\n",
    "contexts = crsb['contents']\n",
    "questions = squad['question']"
   ],
   "id": "fc97a1740e613f16",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T08:29:40.250227Z",
     "start_time": "2024-11-29T08:29:37.372250Z"
    }
   },
   "source": [
    "from cag.vector_candidates.vc import VectorCandidates\n",
    "from cag.gate.vector_candidates import VectorCandidatesGate\n",
    "\n",
    "with open('F:\\\\OneDrive\\\\Desktop\\\\Research\\\\Dataset\\\\CRSB-Embeddings-MPNET.json', 'r') as f:\n",
    "    crsb = json.load(f)\n",
    "\n",
    "crsb_contexts_embeddings = crsb['amazon_rainforest']['contents']\n",
    "crsb_pseudo_queries_embeddings = crsb['amazon_rainforest']['questions']\n",
    "VC = VectorCandidates(contexts=[crsb_contexts_embeddings], questions=[crsb_pseudo_queries_embeddings])\n",
    "\n",
    "Gate = VectorCandidatesGate(vc=VC, embedding_model=embeddings_model)"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:33:31.771015Z",
     "start_time": "2024-11-29T08:33:27.727131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "acc = []\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    a = time()\n",
    "    _, needs_retrieval = Gate(question, policy= 95, threshold= 0.0)\n",
    "    b = time()\n",
    "    acc.append(needs_retrieval)\n",
    "    results.append(b - a)\n",
    "    "
   ],
   "id": "54920389929979da",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:33:41.217405Z",
     "start_time": "2024-11-29T08:33:41.199350Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Mean of the execution : {np.mean(np.array(results))}')",
   "id": "5a9f2b349822f4fd",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:33:42.026504Z",
     "start_time": "2024-11-29T08:33:42.009217Z"
    }
   },
   "cell_type": "code",
   "source": "print(acc.count(False))",
   "id": "28c0dae39939df70",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Speed Test of Adaptive-RAG on Llama 3.2 on Ollama - Intel Core i7 1165G7",
   "id": "353a71b944f7bda3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:36:48.289884Z",
     "start_time": "2024-11-29T08:36:48.284733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def query_classification(context, query):\n",
    "    prompt = f\"\"\"I will give you a context and a query . please determine if the context is related to the query or not. this means that the context can potentially answer the query or not. \n",
    "    first provide the reasons that why the context is related to the query or not; then result a YES or NO answer which determines the context can answer the question or not.\n",
    "    \n",
    "    This is the context :\n",
    "    Context : {context}\n",
    "    \n",
    "    Here is the Query :\n",
    "    Query : {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = prompt.format(context = context, query = query)\n",
    "    \n",
    "    result = llama.invoke(prompt).content\n",
    "    \n",
    "    result = result.lower()\n",
    "    \n",
    "    score = True if result.count('yes') > result.count('no') else False\n",
    "    \n",
    "    return result, score"
   ],
   "id": "29eee4275afcee0d",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T09:02:07.572896Z",
     "start_time": "2024-11-29T08:36:55.592141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "adapt_reasons = []\n",
    "classified = []\n",
    "times = []\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    \n",
    "    a = time()\n",
    "    x, y = query_classification(contexts[i], question)\n",
    "    adapt_reasons.append(x)\n",
    "    classified.append(y)\n",
    "    b = time()\n",
    "    \n",
    "    times.append(b-a)\n",
    "    \n",
    "    print(f'Question {i} processed in {b - a} seconds')\n",
    "    \n",
    "print(np.mean(np.array(times)))"
   ],
   "id": "a29d2e2944ab4e67",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "29cfb69800b0381a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
