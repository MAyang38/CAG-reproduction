{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T15:56:32.580268Z",
     "start_time": "2024-11-25T15:56:05.448822Z"
    }
   },
   "source": [
    "from cag.embeddings import SentenceTransformerEmbeddings\n",
    "from cag.models import ChatOllama\n",
    "\n",
    "embeddings_model = SentenceTransformerEmbeddings('sentence-transformers/all-mpnet-base-v2')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laptopkaran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Laptopkaran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:56:35.915296Z",
     "start_time": "2024-11-25T15:56:35.224229Z"
    }
   },
   "cell_type": "code",
   "source": "model = ChatOllama(model = 'qwen2.5', temprature = 0.01)",
   "id": "d0312c2443bcebdb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:56:50.974220Z",
     "start_time": "2024-11-25T15:56:50.956326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def answer_relevancy(generated_answer, original_query):\n",
    "    \n",
    "    prompt = \"\"\"i will give you a answer , please generate three question which we can derive from that answer.\n",
    "    use this format for generation :  start the generation with \"---\" and end it with \"---\" too ; between the questions you should include \"---\" as well . like this format bellow : \n",
    "    \n",
    "    ---\n",
    "    Question number 1\n",
    "    ---\n",
    "    Question number 2 \n",
    "    ---\n",
    "    Question number 3\n",
    "    --- \n",
    "    \n",
    "    Here is the answer : \n",
    "    Answer : {answer}\"\"\"\n",
    "    \n",
    "    prompt = prompt.format(answer=generated_answer)\n",
    "    \n",
    "    \n",
    "    generated_questions = model.invoke(prompt).content\n",
    "\n",
    "    \n",
    "    generated_questions = [item for item in generated_questions.split('---') if len(item) > 7]\n",
    "\n",
    "    #embed the question\n",
    "    generated_questions = [embeddings_model.embed_query(question) for question in generated_questions]\n",
    "    \n",
    "    #embed the query\n",
    "    original_query = embeddings_model.embed_query(original_query)\n",
    "    \n",
    "    generated_questions, original_query = np.array(generated_questions), np.array(original_query)\n",
    "    \n",
    "    # Normalize vectors\n",
    "    vec1_norm = original_query / np.linalg.norm(original_query)\n",
    "    vec_list_norm = generated_questions / np.linalg.norm(generated_questions, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = np.dot(vec_list_norm, vec1_norm)\n",
    "    \n",
    "    return np.mean(cosine_sim)\n",
    "    "
   ],
   "id": "fbd35b7c67f42147",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:56:51.809563Z",
     "start_time": "2024-11-25T15:56:51.804411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def context_relevancy(retrieved_context, original_query):\n",
    "    \n",
    "    prompt = \"\"\"this is a context relevancy test. for the given context and question , extract each sentence of the context and determine if that sentence can potentially be helpful to answer the question. for every sentence , describe the relevancy of that sentence and answer in YES or NO terms which that sentence can be helpful to answer the question or not. \n",
    "    \n",
    "    use this format : \n",
    "    \n",
    "    Sentence  : a simple description of relevancy to the question : YES or NO\n",
    "    \n",
    "    Here is Question \n",
    "    Question : {query}\n",
    "    \n",
    "    Here is the Context :\n",
    "    Context : {context}\"\"\"\n",
    "    \n",
    "    prompt = prompt.format(query = original_query, context = retrieved_context)\n",
    "    \n",
    "    output = model.invoke(prompt).content\n",
    "    \n",
    "    output = output.lower()\n",
    "    \n",
    "    score = output.count('yes') / (output.count('yes') + output.count('no'))\n",
    "    \n",
    "    return score"
   ],
   "id": "ec587f2a38f15257",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:56:52.441638Z",
     "start_time": "2024-11-25T15:56:52.429796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pseudo_context_generate(query):\n",
    "    prompt = \"\"\"for the given question, generate a context that can potentially answer the question. just generate the context without any other explaination . the context should contain at least 4 sentences \n",
    "    \n",
    "    Here is the Question :\n",
    "    Question : {question}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = prompt.format(question = query)\n",
    "    \n",
    "    output = model.invoke(prompt).content\n",
    "\n",
    "    \n",
    "    return output"
   ],
   "id": "6cb3fec1285214cf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading CRSB and SQUAD",
   "id": "994666f409da7cfc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:56:58.756654Z",
     "start_time": "2024-11-25T15:56:58.728891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json \n",
    "\n",
    "with open('F:\\\\OneDrive\\\\Desktop\\\\Research\\\\Dataset\\\\CRSB-Texts.json', 'r') as f:\n",
    "    crsb = json.load(f)\n",
    "    \n",
    "crsb = crsb['amazon_rainforest']"
   ],
   "id": "9d4667cfacb07c5d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:56:59.846757Z",
     "start_time": "2024-11-25T15:56:59.615031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datasets\n",
    "\n",
    "squad = datasets.load_dataset('rajpurkar/squad')\n",
    "squad = squad['validation'].shuffle()"
   ],
   "id": "33834b8a3fd4acf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since rajpurkar/squad couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at F:\\Models\\huggingface\\datasets\\rajpurkar___squad\\plain_text\\0.0.0\\7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Mon Nov 25 19:23:30 2024).\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:57:10.901272Z",
     "start_time": "2024-11-25T15:57:10.888644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "squad = squad[:100]\n",
    "\n",
    "#this makes squad a dict like object with keys and values , values are lists"
   ],
   "id": "5257223831face75",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:57:12.042269Z",
     "start_time": "2024-11-25T15:57:12.032632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(crsb.keys())\n",
    "print(squad.keys())"
   ],
   "id": "cd97bcda60e083fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['contents', 'questions'])\n",
      "dict_keys(['id', 'title', 'context', 'question', 'answers'])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:57:12.796406Z",
     "start_time": "2024-11-25T15:57:12.783649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(crsb['contents']))\n",
    "print(len(squad['question']))"
   ],
   "id": "76e3730776c5f7b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:57:13.927142Z",
     "start_time": "2024-11-25T15:57:13.908608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contexts = crsb['contents']\n",
    "questions = squad['question']"
   ],
   "id": "7e96a024611d6bf4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG retriever",
   "id": "8bff0943acb3743a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:57:25.714967Z",
     "start_time": "2024-11-25T15:57:15.983804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "retriever = FAISS.from_texts(texts=contexts,\n",
    "                             embedding= embeddings_model)"
   ],
   "id": "c3fdeb3ade1ba53f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG Evaluation on CRSB + SQUAD",
   "id": "99ef35d676ce8882"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-25T15:52:06.536157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from time import time\n",
    "\n",
    "crs = []\n",
    "ars = []\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    \n",
    "    start = time()\n",
    "    retrieved_context = retriever.similarity_search(query=question, k =1)\n",
    "    ar = answer_relevancy(retrieved_context, question)\n",
    "    cr = context_relevancy(retrieved_context, question)\n",
    "    \n",
    "    crs.append(cr)\n",
    "    ars.append(ar)\n",
    "    \n",
    "    end = time()\n",
    "    print(f'Question {i} processed in {end - start} seconds')\n",
    "    print(f'CR score: {cr}, AR score: {ar}')\n"
   ],
   "id": "fe32620f99354600",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from time import time\n",
    "\n",
    "crs = []\n",
    "ars = []\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    \n",
    "    start = time()\n",
    "    retrieved_context = retriever.similarity_search(query=question, k =1)\n",
    "    ar = answer_relevancy(retrieved_context, question)\n",
    "    cr = context_relevancy(retrieved_context, question)\n",
    "    \n",
    "    crs.append(cr)\n",
    "    ars.append(ar)\n",
    "    \n",
    "    end = time()\n",
    "    print(f'Question {i} processed in {end - start} seconds')\n",
    "    print(f'CR score: {cr}, AR score: {ar}')\n"
   ],
   "id": "c4ad70d8d4f99063"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T09:57:15.555427Z",
     "start_time": "2024-11-25T09:57:15.539149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ars, crs = np.array(ars), np.array(crs)\n",
    "\n",
    "print(f'ARs mean : {np.mean(ars)}')\n",
    "print(f'CRs mean : {np.mean(crs)}')"
   ],
   "id": "ed4b2c263865a732",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARs mean : 0.20629166428308185\n",
      "CRs mean : 0.016049019607843138\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CAG Evaluation on CRSB + SQUAD",
   "id": "72430ee04fac7a5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:57:36.167635Z",
     "start_time": "2024-11-25T15:57:33.663408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from cag.vector_candidates.vc import VectorCandidates\n",
    "\n",
    "with open('F:\\\\OneDrive\\\\Desktop\\\\Research\\\\Dataset\\\\CRSB-Embeddings-MPNET.json', 'r') as f:\n",
    "    crsb = json.load(f)\n",
    "    \n",
    "crsb_contexts_embeddings = crsb['amazon_rainforest']['contents']\n",
    "crsb_pseudo_queries_embeddings = crsb['amazon_rainforest']['questions']"
   ],
   "id": "3f1e84d9687c7a8c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:57:38.282095Z",
     "start_time": "2024-11-25T15:57:37.280137Z"
    }
   },
   "cell_type": "code",
   "source": "VC = VectorCandidates(contexts= [ crsb_contexts_embeddings ], questions= [ crsb_pseudo_queries_embeddings ])",
   "id": "fa45e7191da2d90d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:57:39.155289Z",
     "start_time": "2024-11-25T15:57:39.139407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cag.gate.vector_candidates import VectorCandidatesGate\n",
    "\n",
    "gate = VectorCandidatesGate(vc= VC, embedding_model= embeddings_model)"
   ],
   "id": "4b491aeb671a6d7d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-25T16:00:55.897506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "ars = []\n",
    "crs = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    a = time.time()\n",
    "    \n",
    "    needs_retrieval = gate(squad['question'][i])\n",
    "    \n",
    "    if needs_retrieval:\n",
    "        retrieved_context = retriever.similarity_search(query=squad['question'][i], k =1)\n",
    "        ar = answer_relevancy(retrieved_context, squad['question'][i])\n",
    "        cr = context_relevancy(retrieved_context, squad['question'][i])\n",
    "    \n",
    "    else:\n",
    "        pseudo_context = pseudo_context_generate(squad['question'][i])\n",
    "        \n",
    "        ar = answer_relevancy(pseudo_context, squad['question'][i])\n",
    "        cr = context_relevancy(pseudo_context, squad['question'][i])\n",
    "        \n",
    "    ars.append(ar)\n",
    "    crs.append(cr)\n",
    "    b = time.time()\n",
    "    print(f'Question {i} processed in {b - a} seconds')\n",
    "    print(f'CR : {cr} --- AR : {ar}')"
   ],
   "id": "17cbd499420d2c21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 0 processed in 91.55354261398315 seconds\n",
      "CR : 0.16666666666666666 --- AR : 0.7838292693725731\n",
      "Question 1 processed in 103.201819896698 seconds\n",
      "CR : 0.6666666666666666 --- AR : 0.7051831108787031\n",
      "Question 2 processed in 93.35385727882385 seconds\n",
      "CR : 0.125 --- AR : 0.7843428505093316\n",
      "Question 3 processed in 77.26798915863037 seconds\n",
      "CR : 0.5 --- AR : 0.7164826458604162\n",
      "Question 4 processed in 107.1562852859497 seconds\n",
      "CR : 0.2727272727272727 --- AR : 0.6853714530236195\n",
      "Question 5 processed in 86.5181212425232 seconds\n",
      "CR : 0.6666666666666666 --- AR : 0.7831548127337072\n",
      "Question 6 processed in 75.17269492149353 seconds\n",
      "CR : 0.2857142857142857 --- AR : 0.6380235928656545\n",
      "Question 7 processed in 91.82279992103577 seconds\n",
      "CR : 0.3333333333333333 --- AR : 0.4922328638088171\n",
      "Question 8 processed in 70.90986943244934 seconds\n",
      "CR : 0.3333333333333333 --- AR : 0.7368721891085274\n",
      "Question 9 processed in 109.96259093284607 seconds\n",
      "CR : 0.0 --- AR : 0.5358087515057379\n",
      "Question 10 processed in 80.53761553764343 seconds\n",
      "CR : 0.3333333333333333 --- AR : 0.8468483022997102\n",
      "Question 11 processed in 114.82928276062012 seconds\n",
      "CR : 0.1111111111111111 --- AR : 0.603840935755817\n",
      "Question 12 processed in 108.34982204437256 seconds\n",
      "CR : 0.5714285714285714 --- AR : 0.8234341150892862\n",
      "Question 13 processed in 80.54245448112488 seconds\n",
      "CR : 0.2222222222222222 --- AR : 0.7006647154057827\n",
      "Question 14 processed in 70.11829018592834 seconds\n",
      "CR : 0.2 --- AR : 0.6929140192311909\n",
      "Question 15 processed in 108.46597051620483 seconds\n",
      "CR : 0.3333333333333333 --- AR : 0.7267799745095586\n",
      "Question 16 processed in 81.84259867668152 seconds\n",
      "CR : 0.6666666666666666 --- AR : 0.544031852976253\n",
      "Question 17 processed in 74.95867967605591 seconds\n",
      "CR : 0.5 --- AR : 0.649637165923106\n",
      "Question 18 processed in 80.84903383255005 seconds\n",
      "CR : 0.5 --- AR : 0.7191782280984523\n",
      "Question 19 processed in 101.75548005104065 seconds\n",
      "CR : 0.3333333333333333 --- AR : 0.642940433895393\n",
      "Question 20 processed in 96.22492265701294 seconds\n",
      "CR : 0.375 --- AR : 0.7452634375726661\n",
      "Question 21 processed in 84.855886220932 seconds\n",
      "CR : 0.5 --- AR : 0.7485483484437291\n",
      "Question 22 processed in 76.344801902771 seconds\n",
      "CR : 0.3333333333333333 --- AR : 0.7308745091819343\n",
      "Question 23 processed in 81.79795336723328 seconds\n",
      "CR : 0.14285714285714285 --- AR : 0.6708640050079909\n",
      "Question 24 processed in 80.69011569023132 seconds\n",
      "CR : 0.5 --- AR : 0.8106812794728878\n",
      "Question 25 processed in 66.68471550941467 seconds\n",
      "CR : 0.16666666666666666 --- AR : 0.6951021207333703\n",
      "Question 26 processed in 105.34588027000427 seconds\n",
      "CR : 0.6666666666666666 --- AR : 0.6944791154582964\n",
      "Question 27 processed in 75.86568593978882 seconds\n",
      "CR : 0.16666666666666666 --- AR : 0.6894122004429267\n",
      "Question 28 processed in 77.06437063217163 seconds\n",
      "CR : 0.75 --- AR : 0.6033724462454301\n",
      "Question 29 processed in 65.74239706993103 seconds\n",
      "CR : 0.3333333333333333 --- AR : 0.7066123046487375\n",
      "Question 30 processed in 96.83335494995117 seconds\n",
      "CR : 0.6 --- AR : 0.7175303427907185\n",
      "Question 31 processed in 80.15484642982483 seconds\n",
      "CR : 0.25 --- AR : 0.713762951512808\n",
      "Question 32 processed in 81.8916974067688 seconds\n",
      "CR : 0.2857142857142857 --- AR : 0.7017158490876728\n",
      "Question 33 processed in 99.41024136543274 seconds\n",
      "CR : 0.18181818181818182 --- AR : 0.5992596194550325\n",
      "Question 34 processed in 81.01569867134094 seconds\n",
      "CR : 0.2857142857142857 --- AR : 0.881181641780424\n",
      "Question 35 processed in 88.05914258956909 seconds\n",
      "CR : 0.5714285714285714 --- AR : 0.617084165973205\n",
      "Question 36 processed in 86.98517155647278 seconds\n",
      "CR : 0.14285714285714285 --- AR : 0.5677787991278331\n",
      "Question 37 processed in 86.42932415008545 seconds\n",
      "CR : 0.3333333333333333 --- AR : 0.91821228283867\n",
      "Question 38 processed in 90.81603574752808 seconds\n",
      "CR : 0.2857142857142857 --- AR : 0.6941846368374321\n",
      "Question 39 processed in 73.52694344520569 seconds\n",
      "CR : 0.16666666666666666 --- AR : 0.8642386746128038\n",
      "Question 40 processed in 69.2505533695221 seconds\n",
      "CR : 0.2 --- AR : 0.8284145236044195\n",
      "Question 41 processed in 91.01619267463684 seconds\n",
      "CR : 0.2222222222222222 --- AR : 0.6158690311838172\n",
      "Question 42 processed in 84.55257964134216 seconds\n",
      "CR : 0.2 --- AR : 0.7510942972439597\n",
      "Question 43 processed in 75.1544508934021 seconds\n",
      "CR : 0.23076923076923078 --- AR : 0.7935381804585183\n",
      "Question 44 processed in 49.97923183441162 seconds\n",
      "CR : 0.2 --- AR : 0.6403091267196023\n",
      "Question 45 processed in 76.46984028816223 seconds\n",
      "CR : 0.08333333333333333 --- AR : 0.8651094347031467\n",
      "Question 46 processed in 87.71260237693787 seconds\n",
      "CR : 0.125 --- AR : 0.661059208626047\n",
      "Question 47 processed in 90.66180658340454 seconds\n",
      "CR : 0.5 --- AR : 0.7452259008362359\n",
      "Question 48 processed in 82.65221691131592 seconds\n",
      "CR : 0.18181818181818182 --- AR : 0.7034641904996844\n",
      "Question 49 processed in 69.70830392837524 seconds\n",
      "CR : 0.16666666666666666 --- AR : 0.729736480116327\n",
      "Question 50 processed in 90.83188962936401 seconds\n",
      "CR : 0.6 --- AR : 0.654054492109763\n",
      "Question 51 processed in 66.49539804458618 seconds\n",
      "CR : 0.14285714285714285 --- AR : 0.7878393139865345\n",
      "Question 52 processed in 79.30959701538086 seconds\n",
      "CR : 0.75 --- AR : 0.5217964549679912\n",
      "Question 53 processed in 95.85346341133118 seconds\n",
      "CR : 0.125 --- AR : 0.7102367858488514\n",
      "Question 54 processed in 87.6424777507782 seconds\n",
      "CR : 0.1111111111111111 --- AR : 0.8292593232003286\n",
      "Question 55 processed in 86.85241937637329 seconds\n",
      "CR : 0.14285714285714285 --- AR : 0.6732101260218925\n",
      "Question 56 processed in 90.52294659614563 seconds\n",
      "CR : 0.8 --- AR : 0.7181340585163767\n",
      "Question 57 processed in 85.40303659439087 seconds\n",
      "CR : 0.375 --- AR : 0.744309958333799\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ars, crs = np.array(ars), np.array(crs)\n",
    "\n",
    "print(f'ARs mean : {np.mean(ars)}')\n",
    "print(f'CRs mean : {np.mean(crs)}')"
   ],
   "id": "a0f32a2fa00e59d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
